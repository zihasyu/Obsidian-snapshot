
# 题目

## 需求

百亿级个固定长度8KB（8192字节）大小的原始数据块dataBlock（也可能是4/16/32KB大小，但全系统所有原始数据块大小保持一致，每个dataBlock有唯一编号blockId），首先利用聚类分组算法，将最多不超过16个原始数据块分为一组，然后再利用LZ77/LZ4等或其他无损压缩算法，对每个分组进行合并压缩，构造出压缩数据块zipBlock，从而最终形成压缩数据集合zipData用于存储。

假设总计有_**Z**_个数据块_**Xi**_（_**i**_ = 0, 1, 2, ......, _**Z**_-1），将其分组，允许的最大分组数为_**U**_（2~16，即每个分组包含_**U**_个相似数据块）_**，**_分组的方法共计有_**W**_ = _**C**_(_**Z, U**_)个，当_**Z**_值达到百亿量级时（百TB级数据量），_**W**_值将非常大，工程上不可计算，因此无法求得分组结果的最优解，只能计算出次优解。

**期望：zipData的压缩比尽可能大（压缩比K=压缩前总数据量/压缩后总数据量）。**

## Metrics

### 分组收益R0

每个chunk单独LZ4压缩的size / 分组后的压缩size

**考核标准：**

及格 2.0 优秀 2.8

### BW

单位时间内可以处理的数据量 单位GB/s

**考核标准：**

及格 1.5GB/s 优秀 3GB/s

### 存储开销M

其实就是元数据存储开销，每个chunk最大允许拥有64B的元数据，还有1GB的浮动误差。

M=e*N+f

**考核标准：**

e 及格 64B 优秀 48B

f 及格 1GB 优秀 N/A

## 难点

1. 数据量不允许暴力寻找全局最优，可能的分组组合数太多，计算开销不可接受。
    
2. 相似性度量的方法如何选择？和delta compression选择base chunk不同，需要度量俩个chunk的相似程度，而不是只有相似或不相似俩个选项。（Palantir）
    
3. 分组策略如何设置？每个组是否固定大小？如果不固定，组大小的上限和下限如何设置？组内的chunk应该按照什么顺序组织？在chunk相似性度量确定后，应该如何选择落入哪一组？
    
4. 如果使用feature-based方法（似乎绕不开），那么如何保证元数据开销在规定的范围内？
    

# Baseline

## VMDK

### LZ4Compare

```SQL
2024-07-08 08:27:46 <Chunker>: chunking done.
2024-07-08 08:27:46 <Chunker>: thread exit.
2024-07-08 08:27:47 <lz4Compare>: Total logical size: 17280008192, total compressed size: 10705032421, compression ratio: 1.61
2024-07-08 08:27:47 <LZ4Cluster>: Chunk Num is 2109376
2024-07-08 08:27:47 <LZ4Cluster>: Cluster Num is 0
2024-07-08 08:27:47 <LZ4Cluster>: Total logical size is 17280008192
2024-07-08 08:27:47 <LZ4Cluster>: Total compressed size is 10705032421
2024-07-08 08:27:47 <LZ4Cluster>: Compression ratio is 1.6142
```

### LZ4Baseline

```SQL
2024-07-07 20:10:23 <Chunker>: chunking done.
2024-07-07 20:10:23 <Chunker>: thread exit.
2024-07-07 20:10:46 <lz4Baseline>: 575099 feature with only one chunk and total feature num is 656277
2024-07-07 20:10:46 <lz4Baseline>: Throughput is 1.858843 GiB/s
2024-07-07 20:10:46 <LZ4Cluster>: Chunk Num is 2109376
2024-07-07 20:10:46 <LZ4Cluster>: Cluster Num is 131835
2024-07-07 20:10:46 <LZ4Cluster>: Total logical size is 17280008192
2024-07-07 20:10:46 <LZ4Cluster>: Total compressed size is 9786677964
2024-07-07 20:10:46 <LZ4Cluster>: Compression ratio is 1.7657
```

## WEB

### LZ4Compare

```SQL
2024-07-07 15:00:16 <Chunker>: chunking done.
2024-07-07 15:00:16 <Chunker>: thread exit.
2024-07-07 15:00:16 <lz4Compare>: Total logical size: 2869463040, total compressed size: 1550184281, compression ratio: 1.85
2024-07-07 15:00:16 <LZ4Cluster>: Chunk Num is 350277
2024-07-07 15:00:16 <LZ4Cluster>: Cluster Num is 0
2024-07-07 15:00:16 <LZ4Cluster>: Total logical size is 2869463040
2024-07-07 15:00:16 <LZ4Cluster>: Total compressed size is 1550184281
2024-07-07 15:00:16 <LZ4Cluster>: Compression ratio is 1.85
```

### LZ4Baseline

```SQL
2024-07-07 20:11:26 <Chunker>: chunking done.
2024-07-07 20:11:26 <Chunker>: thread exit.
2024-07-07 20:11:29 <lz4Baseline>: 30191 feature with only one chunk and total feature num is 37430
2024-07-07 20:11:29 <lz4Baseline>: Throughput is 0.693177 GiB/s
2024-07-07 20:11:29 <LZ4Cluster>: Chunk Num is 350277
2024-07-07 20:11:29 <LZ4Cluster>: Cluster Num is 21892
2024-07-07 20:11:29 <LZ4Cluster>: Total logical size is 2869463040
2024-07-07 20:11:29 <LZ4Cluster>: Total compressed size is 437340799
2024-07-07 20:11:29 <LZ4Cluster>: Compression ratio is 6.5612
```

## Ubuntu(iso)

### LZ4Compare

```SQL
2024-07-07 15:03:00 <Chunker>: chunking done.
2024-07-07 15:03:00 <Chunker>: thread exit.
2024-07-07 15:03:00 <lz4Compare>: Total logical size: 5017356288, total compressed size: 5000103062, compression ratio: 1.00
2024-07-07 15:03:00 <LZ4Cluster>: Chunk Num is 612471
2024-07-07 15:03:00 <LZ4Cluster>: Cluster Num is 0
2024-07-07 15:03:00 <LZ4Cluster>: Total logical size is 5017356288
2024-07-07 15:03:00 <LZ4Cluster>: Total compressed size is 5000103062
2024-07-07 15:03:00 <LZ4Cluster>: Compression ratio is 1.0004
```

### LZ4Baseline

```SQL
2024-07-07 20:06:45 <Chunker>: chunking done.
2024-07-07 20:06:45 <Chunker>: thread exit.
2024-07-07 20:06:47 <lz4Baseline>: 413494 feature with only one chunk and total feature num is 415344
2024-07-07 20:06:47 <lz4Baseline>: Throughput is 2.492380 GiB/s
2024-07-07 20:06:47 <LZ4Cluster>: Chunk Num is 612471
2024-07-07 20:06:47 <LZ4Cluster>: Cluster Num is 38279
2024-07-07 20:06:47 <LZ4Cluster>: Total logical size is 5017356288
2024-07-07 20:06:47 <LZ4Cluster>: Total compressed size is 4994861301
2024-07-07 20:06:47 <LZ4Cluster>: Compression ratio is 1.0045
```