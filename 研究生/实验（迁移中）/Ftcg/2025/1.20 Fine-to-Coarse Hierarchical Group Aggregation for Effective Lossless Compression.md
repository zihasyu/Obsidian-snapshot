
## 0. 研究分组无损压缩的动机

### 0.1 做分组无损压缩的优势：

- **分组无损压缩比起顺序无损压缩的优势**：将相似度较高的块聚集到一起，能提升压缩率。（但迁移压缩同样是把高相似度的块聚到一起，以此来重构文件）
    
- **分组无损压缩比起迁移无损压缩的优势**：能利用多线程提高压缩速率，更适合需要高性能压缩的场景。即可以说分组无损压缩是顺序无损压缩（更注重性能）和迁移无损压缩（更注重压缩率）的**trade-off**。
    

### 0.2 多线程压缩的动机：（补个实验，此外要把lz4换成压缩率更高的deflate算法或者给lz4调参为压缩率高的版本）

#### 补实验图，摆下压缩时间占比

- 在选用注重压缩率，压缩性能差的算法时，多线程能有效提升压缩性能。
    
- 此外在分组压缩中，两个组之间不进行去冗余，组间不存在依赖关系。即存在多线程压缩的可行性。
    

### 0.3 **为什么以8为分组内块的上限**：（有没有更好的解释？）

- 因为64KiB=8*8KiB是LZ4压缩的默认滑窗大小。
    
- 多线程工作中，我们希望每个线程的工作量趋于一致。**（牵强）**
    

  

1.2和1.3有些牵强，本质是给为什么做分组压缩找大于迁移压缩的优势区间， 两者的差异在于①分组压缩只对组内进行无损压缩去重，而迁移压缩除了组内外，兼顾了组间，更多的利用到了无损压缩滑窗。②分组压缩对每个分组有上限的限制，迁移压缩是没有的。

1. ## 相关工作与基础知识
    

### 1.1 无损压缩（lz4/lz77）

### 1.2 迁移压缩

### 1.3 基于特征值寻找相似块

  

2. ## 分组压缩面临的问题
    

### 2.1 一个怎样的分组才算好压缩的分组

对此做了一个实验：生成了一个8kb的块，并基于此数据块随机修改10%~90%的内容作为实验数据，利用这些块来随机组成不同的分组，来比较他们的压缩率。

![](https://uestc.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjA1Yjc5ZWQ4NjdiZTBjOTU1Zjk1NDcwZWZjNjM3NjBfMGtGbXBYWXFGa2Y4YmVYcmd3NnQ2NjdWd1RMdHphV0xfVG9rZW46RmtFZGJTdVkwb1lqQXR4RHI5QWNTVVFpbmlnXzE3NDIzMTI5Mzk6MTc0MjMxNjUzOV9WNA)

由图可以看出当块之间已知有相似部分时，**分组数量越接近上限，整体的reduction size越高**

![](https://uestc.feishu.cn/space/api/box/stream/download/asynccode/?code=YTEzYzk3ODA3YjQzZmRmZTE0YjliZWRlOWY2NGI5YWJfaG5VQjNlWHFYY1BGaDJJYlVHM3Y4R0kxQlppUXJLVzlfVG9rZW46T05QWGJyaHlub21LSFd4WUpaS2NSMG93bkpkXzE3NDIzMTI5Mzk6MTc0MjMxNjUzOV9WNA)

由图可以看出，分组中的**数据块之间的相似度越高，分组的整体压缩率更好**

  

### 2.2 贪心方法难以在线性时间内完成分组

贪心方法在每步分组前，需先遍历地进行无损压缩尝试。因此时间复杂度过高，难以投入生产使用。

#### 补表格，介绍下传统方法和贪心的耗时。

![](https://uestc.feishu.cn/space/api/box/stream/download/asynccode/?code=MmJkZWFlMWU1YzNjZTM5MWU2ZDlkOTU0ZmM5NzQ1OTFfS2VLNndVeUt1VGZkdzFBczlZOFd4b1ZZcE53dkF4QU1fVG9rZW46UnJ3N2JzYW80bzlta1J4MkxaSGNKTjJTbkdlXzE3NDIzMTI5Mzk6MTc0MjMxNjUzOV9WNA)

1024个块进行贪心地分组压缩

此外，通过每步reduce size的图可以看出，贪心方法优先聚合相似度更高的块，再拿相似度较低的块去填充未满分组，直至最后剩余一些相似部分过少的块单独压缩。

  

### 2.3 传统特征值方法难以衡量数据块之间的相似度

传统的特征值提取方法（odess）在同一特征（SF）下的块固然是相似的，但这种相似难以**区分相似度级别，**无法最大化提升压缩率。

#### 补实验图来argue（x轴steps，y轴reduce size，两条线分别是贪心和Odess，贪心是递减曲线，Odess是波动较大无明显趋势的曲线）

由2.1-2.3可以看出，为使分组压缩率提升

①我们必须要尽可能的将更相似的数据块聚合在一起，

②没有更相似的数据块时，再去将相似度较低的数据块（至少已知有相似部分）填充进来使得平均每个分组内的块数变多。

3. ## Ftcg-Design
    

### 3.0 Overview

### 3.1 HSF 线性时间内区分相似度级别

我们要寻找一种能够**区分相似度级别**的方式来最大化利用压缩滑窗的优势，

于是我们提出了层次特征这一概念，将odess的每个块的12个原始特征进行一定的组合和线性变换得到三个层次特征值

![](https://uestc.feishu.cn/space/api/box/stream/download/asynccode/?code=MzIxYmNhM2MzMDY1N2ZmNGJjODIxZDg3YTc5ZjFhZjlfNGFzdnliU2k5dWdVWEtwNEF2aXRVemNjcnRoMmZyQ29fVG9rZW46VkRBbmJIODByb0JTcWx4ZUFFbmNPMFh2bndnXzE3NDIzMTI5Mzk6MTc0MjMxNjUzOV9WNA)

  

通过层次特征，我们**在聚合数据块的时候可以分层次来聚合，由细粒度到粗粒度.**

![](https://uestc.feishu.cn/space/api/box/stream/download/asynccode/?code=NDZiYmRiM2NjMzBkZjM0NzJkMzNkMjg2MzRkNTQ5NGJfQUxjU2VsY3Azb3VIUEhQN2poY2FxRWV3aGlHQTlMRHhfVG9rZW46QUIxMWJaZW1hb1FmdEx4cXFpM2NRT2xqbkVPXzE3NDIzMTI5Mzk6MTc0MjMxNjUzOV9WNA)

我们用HSF这种方式，一定程度上将相似度高的块优先聚合，相似度较低的块滞后聚合，但为满足另一个需求【使得平均每个分组内的块数变多】，我们需要在每层分组结束进入下一层merge时，利用**近似贪心**的方法将次级分组合并，来使得某次合并得出的组数尽可能少。

### 3.2 HSFRank 修改数据结构，利用排序代替多次分组merge，减少时间开销

移除SFa SFb两个table,只保存SFc-Table。

直接对SFc-Table中所有块以SFc的大小为依据排序，此时SF3相等的chunk会相邻，SF2相等SF3不等的分组也会相邻，SF1相等SF2不等的分组同理，此时这种相邻也是一种有相似度优先级的“相邻”。

![](https://uestc.feishu.cn/space/api/box/stream/download/asynccode/?code=NjJhOGRmNTRmN2JmNDBiNTdmYWQyNDM0NGMwY2VjMGVfa2dWZUFTa2EyeXI0aHFOZWUzQ1o2cTNzbTRTTE94S0xfVG9rZW46WEI0bGJzdk5mb1c2dUF4NVZBbmNMcEQzbkhkXzE3NDIzMTI5Mzk6MTc0MjMxNjUzOV9WNA)

  

于是可以节省掉两次贪心merge的过程，直接对排序后 SFa相同 无论SFb SFc是否相同的chunks进行模8分组，只要SFa相同就能保证有一定的相似部分，模8分组前的排序能尽可能将相似度更高的块相邻，本质上用一次排序代替了两次贪心merge。

|   |   |   |   |
|---|---|---|---|
|Compression Ratio|Baseline(Odess)|Design1|Design2（只优化开销）|
|Cassandra|2.04491|2.87699|2.87681|
|LKT|2.61168|3.96462|3.9642|
|WEB|6.12281|8.94193|8.94187|
|Chromium|3.77992|5.24633|5.24677|

|   |   |   |   |
|---|---|---|---|
|Total Time|Baseline(Odess)|Design1|Design2（只优化开销）|
|Cassandra|13s|17s|10s|
|LKT|6s|9s|6s|
|WEB|66s|188s|70s|
|Chromium|85s|171s|108s|

由实验结果可得出，该做法在几乎不损失压缩率的前提下，使性能得到了较大提升。

### 3.3 Sub-chunk 处理分组不完全的问题

上述分组完成后，即使是最粗粒度的特征值，也暴露出一些“孤立块”（一个特征下面只对应了一个数据块）和一些分组大小不足上限的分组（在LKT等数据集中该部分数据块的占比超过25%），这意味着无法通过特征将该数据块分到任意一个分组中，为了解决这个问题，我们提出了子块抽样的方法：

在固定长块内容运行期望size较小的fastcdc，可以得出若干切点hash满足一定规律的sub-chunk。选取size最大的sub-chunk（也可以是fp最小）作为代表块，此时子块的两个切点hash都满足一定规律。基于该子块的SF进行分组。

4. ## Evaluation
    

|   |   |   |   |   |   |
|---|---|---|---|---|---|
|Compression Ratio|Baseline(Odess)|Design1|Design2（只优化开销）|Design3|improvement|
|Cassandra|2.04491|2.87699|2.87681|2.9776|45.61%|
|LKT|2.61168|3.96462|3.9642|4.08721|56.50%|
|WEB|6.12281|8.94193|8.94187|9.16804|49.74%|
|Chromium|3.77992|5.24633|5.24677|5.37976|42.32%|

|   |   |   |   |   |
|---|---|---|---|---|
|Total Time|Baseline(Odess)|Design1|Design2（只优化开销）|Design3|
|Cassandra|13s|17s|10s|15s|
|LKT|6s|9s|6s|8s|
|WEB|66s|188s|70s|73s|
|Chromium|85s|171s|108s|126s|

  

## 一些失败的尝试

1. 试图寻找特征之间的关系（×）
    
2. 试图结合locality的方法（×）
    
3. 试图采用贪心的方法（可能能拿来当2.2）
    
4. 试图采用字节向量的方法（×）
    

## TODO For Prototype：

- 把group相关从string改为uint64_t的数组，维护相关操作
    
- 不需要FPindex里存vector大改。
    
- 上述dedup大改只应用到了design1，后面同步一下
    
- 最后对finishedgroup的压缩也可以抽象到父类
    
- 把SF->FP表改成 SF->chunkid即可，能8B->32B变为8B->8B节省很多存储开销，此外不存储重复块后不再需要遍历FP表去做操作，而是在接受chunk时先判断是否重复，不重复则赋予id，否则不赋予id，而是在recipe中记录重复的id即可。
    
- 补足design0-design3：
    
- design0功能
    
- design2功能
    
- design3功能
    
- 减少因代码复用带来的修改难度
    
- 实现压缩持久化
    
- 设计recipe：**recipe**还是以filename->id为主导+每个file的最后一个chunksize，还是记录在最终压缩文件中的container和偏移量即可。弱化group的概念。
    
- 完成restore：为了体现压缩前是固定长的这个概念，所以在压缩好往外存里存的时候记得个chunkid-index去记录下该chunk位于第几个containers的**第几个解压后的块**。而不是记录压缩后的offset。【当然后果是restore的时候很吃内存】
    
- 完善对index的统计
    
- 完善log
    
- **用/0补齐每个文件的最后一个chunk**，这样就不需要记录chunksize了，并且在restore时也能减少工作量。为了能正确还原文件，需要记录每个文件最后一个chunk的**实际chunksize到recipe中**。【但这样是否合适，存疑】
    
- 用命令行指定是否打开8合1，默认不开
    
- 用命令行指定是否开启restore，默认不开
    
- 给要8合1的版本加finishedgroup的lastfit
    

  

- 国内外研究现状