# 疑问

## Compare with the baselines

FastCDC+finesse, FastCDC+odess, MTar+finesse, MTar+odess, Ours
### Overall compression ratio(baseline ours)
Table（放总的）或 per version 放五条线的折线图
### Reduction size breakdown(dedup local delta)

***疑问：Table放size?还是逐步放ratio?只放ours还是要和其他的比，以及放这个结果是否需要有insight。还是放了就行。（之前这个地方是从size改ratio，又从ratio改size，最后也没订下来）***

### performance

per version 放五条线的折线图

***疑问：mtar重构文件的时间是否计入在内，是把mtar重构文件作为一个系统发生前的步骤，还是也并入系统内的步骤***
### index overhead

柱子图或者table
***疑问：ID+FP+SF这个组合其实不管在哪个方法中，都比FP+SF的开销小，实际上应该是我们的方法在IDindex里多加一个uint64_t的namehash值和两个bool量。但之前测量的时候，吴俊让baseline用FP+SF，我们的方法用ID+FP+SF这样不同的index组合去测，我觉得不太合理
解释下为什么ID+FP+SF overhead比FP+SF低:***

```c++
define ChunkInfo X
define FP 32B
define SF 8B
define ID 8B

ID+FP+SF{
IDIndex:(ID->ChunkInfo)8B->X  per unique chunk
FPIndex:(FP->ID)32B->8B  per unique chunk
SFIndex:(SF->ID)8B->8B  per base chunk has 3
}
(48B+X)*uniqueChunkNum
16B*3*basechunkNum

FP+SF{
FPIndex:(FP->ChunkInfo)32B->(X+8B)  per unique chunk
SFIndex:(SF->FP)8B->32B  per base chunk has 3
}
(40B+X)*uniquechunkNum
40B*3*basechunkNum

```

## Component Analysis
### 1. For SA chunking：range Meta chunk size
 不同Metadata chunk size粒度下的
OCR （甚至还可以加 avgChunkSize ,overhead和performance）

-H参数 服务器挂在server3
### 2. For Metadata-guided: Is Metadata-guided

是否打开Metadata-guided分别跑一轮perverion的storage变化，来证明该寻找相似块方法是有收益的，而非为了设计而设计
-t 参数 服务器挂在node2

### 3. 1 For False filter: Is false filter（疑问：这个实验是不是放在design3的位置比较好，提出做false filter的动机，但讲design的部分能放实验吗？）

node 3服务器 -a -b参数
接受所有能找到的delta，与有false filter的对比实验。
### 3.2 For False filter: range false filter
固定值的传统false filter与我们3.3设计的动态false filter去对比


# 实验

## 0. Compare with the baselines
### Overall compression ratio(baseline ours)
Table:
SA+odess SA+Meta SA+Meta+Odess
### Reduction size breakdown(meta file \* dedup local delta)
Table
### performance
多个折线图
### index overhead
柱子图或者table

## 1. For SA chunking
### 1.1 range Meta chunk size
- [x] 不同Metadata chunk size粒度下的
OCR 和 avgChunkSize （甚至还可以加overhead和performance）
~~chunkNum breakdown~~
-H参数 server3
## 2. For Metadata-guided
### 2.1 Is Metadata-guided
- [x] 是否打开Metadata-guided分别跑一轮perverion的storage变化，来证明该寻找相似块方法是有效的
-t 参数 node2
## 3. For False filter

node 3 -a -b参数
### 3.1 Is false filter
- [x] 3.1证明需要一个false filter，接受过多的delta反而会降低最后的storage//还可以考虑加DCC
完全舍弃false filter后（即全部接受）的per version 的 storage变化
再加一个有false filter的线
y=OCR
x=version
最后是两条折线图
### 3.2 range false filter
- [x] 3.2证明本文设计的false filter能给大部分数据集做一个还ok的过滤机制
false filter是基于统计数据的过滤，这里改为固定值的过滤，给出一个变化范围。并把false filter这个动态变化的方案作一条虚线插进来

