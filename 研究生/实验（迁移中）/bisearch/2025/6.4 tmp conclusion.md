
```
\begin{abstract}
Tar archives are widely used for data backup, yet traditional data reduction approaches treat them as generic byte streams, overlooking valuable semantic information embedded within the format. We present FineTAR, a semantics-aware data reduction system for tar archives that makes three key contributions: (1) a chunking strategy that preserves file boundaries to eliminate cross-file boundary shifts, (2) a hybrid resemblance detection mechanism combining metadata-based and feature-based techniques, and (3) a dynamic false positive filtering mechanism that optimizes long-term compression efficiency.

Extensive evaluation across ten real-world datasets demonstrates that FineTAR consistently outperforms state-of-the-art approaches, achieving 12.8\% to 53\% higher compression ratios compared to baseline systems. Our results show that leveraging format-specific optimizations substantially improves overall storage efficiency without compromising processing throughput, establishing a new direction for format-aware data reduction in backup systems.
\end{abstract}
```

```
\section{Introduction}

Data backup systems routinely employ tar (Tape Archive) format to consolidate multiple files into a single archive for simplified management and preservation of file metadata. As data volumes continue to expand, ensuring efficient storage of these tar archives has become increasingly critical. Contemporary backup systems typically employ deduplication and delta compression as their primary data reduction strategies, yet these techniques often yield suboptimal results when applied to tar archives without format-specific optimizations.

\paragraph{Limitations of Existing Approaches.}
Traditional content-defined chunking (CDC) methods treat tar archives as undifferentiated byte streams, disregarding their inherent file-based structure. This oversight leads to the boundary-shift problem, where minor modifications to files early in an archive cause cascade effects that prevent deduplication of unchanged content in subsequent portions. Additionally, resemblance detection techniques used to identify similar non-duplicate chunks for delta compression rely heavily on content-based features, making them overly sensitive to minor data modifications that frequently occur between backup versions.

Previous work has attempted to address these limitations through format reconstruction approaches (e.g., MTar~\cite{lin2015metadata}), which require costly conversions between standard tar and specialized formats. Such methods introduce significant processing overhead and fail to fully exploit the semantic information already available within tar archives. While these techniques yield moderate improvements in compression efficiency, they fall short of achieving optimal storage reduction while maintaining high performance.

\paragraph{Our Approach.}
We introduce FineTAR, a semantics-aware data reduction system specifically designed for tar archives. Our approach differs fundamentally from previous work by directly leveraging the inherent structure and metadata within tar archives to improve both deduplication and delta compression effectiveness without requiring format conversion. FineTAR makes three key technical contributions:

First, we propose a semantics-aware chunking strategy that aligns chunk boundaries with file boundaries within tar archives. By exploiting tar's well-defined header structure to precisely identify file regions, our approach eliminates boundary shifts between versions and creates semantically meaningful chunks that better preserve content similarity.

Second, we develop a hybrid resemblance detection mechanism that combines metadata-based and feature-based approaches to identify similar chunks more effectively. By leveraging filename information that typically remains stable across versions, our system can establish reliable connections between chunks even when content changes significantly disrupt feature-based matching.

Third, we introduce a dynamic false positive filtering mechanism that optimizes long-term compression efficiency across multiple backup versions. Rather than naively maximizing immediate delta compression coverage, our system selectively preserves high-quality base chunks when they offer better potential for compressing future versions, using an adaptive threshold derived from observed statistical properties during the backup process.

\paragraph{Results.}
We evaluated FineTAR against state-of-the-art approaches using ten real-world datasets that represent diverse software development patterns and web content evolution. Our results demonstrate that FineTAR consistently outperforms all baselines, achieving overall compression ratios that are 12.8\% to 53\% higher than the best alternative methods. Moreover, our system maintains competitive or superior throughput despite providing significantly higher delta compression coverage (up to 169.78\% improvement), while simultaneously reducing index overhead by up to 76.8\% compared to baseline approaches.

The remainder of this paper is organized as follows: Section~\ref{sec:background} provides essential background on tar archives and data reduction techniques; Section~\ref{sec:design} details the design of FineTAR; Section~\ref{sec:implementation} describes our implementation; Section~\ref{sec:evaluation} presents our experimental evaluation; and Section~\ref{sec:conclusion} concludes with a summary of our contributions.
\end{section}

```

```
\section{Conclusion}
\label{sec:conclusion}
This paper presented FineTAR, a semantics-aware data reduction system for tar archives that addresses the fundamental limitations of generic deduplication approaches. Our semantics-aware chunking strategy eliminates boundary-shift problems by preserving file boundaries, while our header aggregation technique simultaneously reduces index overhead and improves compression efficiency. The hybrid resemblance detection mechanism significantly enhances delta compression coverage by combining metadata-based and feature-based approaches, and our dynamic false positive filtering mechanism optimizes long-term compression efficiency across multiple backup versions. Extensive evaluation across diverse datasets demonstrates FineTAR's consistent performance advantages, validating the effectiveness of combining semantic awareness with hybrid resemblance detection and suggesting promising directions for format-specific data reduction techniques in backup systems.
\end{section}
```