
design2 的完整动机：
```
% While semantic-aware chunking effectively prevents cross-file boundary shifts, it introduces a new challenge: reduced fine-grained data reduction within modified files. Unlike traditional CDC, which may preserve some chunk boundaries even when files change, semantic-aware chunking treats modified files as entirely new chunks. This limitation is particularly significant for File-chunks, which represent entire files.

  

% To address this challenge without sacrificing the boundary stability benefits, we leverage another characteristic of tar archives: the rich metadata information contained in file headers. Our Metadata-guided Resemblance Detection approach enables efficient delta compression by rapidly identifying similar chunks based on metadata similarity, complementing the coarse-grained deduplication achieved through semantic-aware chunking.

  

% Traditional feature-based approaches for delta compression face limitations when applied to file-level deduplication in tar archives. While these methods can effectively identify similar chunks based on content patterns, they fail to maintain crucial version relationships between modified files. When employing feature-based methods for file-level incremental compression, we anticipate two primary matching scenarios:

  

% \begin{itemize}

% \item \textbf{File creation from templates}, where newly created files are expected to match their template files. This allows storing only the differences between the new file (and its subsequent versions) and the template file (e.g., File B $\rightarrow$ File A, File B' $\rightarrow$ File A). We classify this as \textbf{Case 1}.

  

% \item \textbf{File modification}, where modified files are expected to match their previous versions. When a file undergoes changes, the incremental compression paradigm suggests that the most suitable base file would be the file's pre-modification version (e.g., File A' $\rightarrow$ File A, File C' $\rightarrow$ File C), which we designate as \textbf{Case 2}. However, since feature-based methods rely entirely on content similarity with relatively high matching thresholds, situations arise where even moderate modifications prevent successful matching, resulting in lost compression opportunities (File D' failing to match File D). We identify this scenario as \textbf{Case 3}.

% \end{itemize}

  

% \begin{figure}[t]

%     \centering

%     \includegraphics[width=\linewidth]{pic/motivation/deltamotivation.png}

%     \caption{Cases 3 collectively represent substantial compression opportunities that traditional approaches struggle to identify.}

%     \label{fig:deltamotivation}

% \end{figure}

% Our analysis reveals three distinct matching scenarios:

  

% \begin{itemize}

%     \item \textbf{Case 1 (Template Matching)}: A new file matches its template (e.g., File B $\rightarrow$ File A). This represents the strength of feature-based methods.

%     \item \textbf{Case 2 (Version Matching)}: A modified file matches its previous version (e.g., File A' $\rightarrow$ File A). While feature-based methods can achieve this match, they incur unnecessary computational overhead.

%     \item \textbf{Case 3 (Missed Version Matching)}: A modified file fails to match its previous version despite moderate changes (e.g., File D' $\nrightarrow$ File D). This represents a significant loss of compression opportunities.

% \end{itemize}

  

% \begin{table}[t]

% \centering

% \small

% \setlength{\tabcolsep}{1pt}

% \begin{tabular}{|c|c|c|c|c|c|c|c|}

% \hline

% Dataset & Case 1 & Case 2 & Case 3 & Dataset & Case 1 & Case 2 & Case 3 \\

% \hline

% \hline

% Linux & 9.8 & 34.8 & 55.3 & Automake & 41.6 & 30.1 & 28.5 \\ \hline

% Web & 53.6 & 0.9 & 45.6 & Bash & 15.3 & 37.5 & 47.2 \\ \hline

% Chromium & 35.9 & 0.4 & 63.7 & Coreutils & 21.3 & 33.4 & 45.3 \\ \hline

% Glibc & 27.1 & 34.9 & 38.0 & Fdisk & 20.8 & 32.7 & 46.5 \\ \hline

% GCC & 23.2 & 20.0 & 56.8 & Smalltalk & 11.0 & 40.5 & 48.5 \\ \hline

% \end{tabular}

% \caption{Distribution of Matching Cases Across Datasets (\%)}

% \label{tab:matching-cases}

% \end{table}

  

% Our experimental evaluation across multiple datasets demonstrates that Case 2 and Case 3 collectively account for 45.3-95.6\% of matching scenarios (Table~\ref{tab:matching-cases}), with Case 3 alone representing 28.5-63.7\% of cases. This reveals a fundamental limitation of content-only approaches - they cannot reliably maintain version relationships between modified files, even when changes are minimal.

  

% The prevalence of Case 3 scenarios directly impacts both storage efficiency and performance. Each missed match represents lost compression opportunities, while the computational resources expended on failed feature calculations yield no benefit. This motivates our metadata-guided approach, which leverages the inherent naming structure of tar archives to maintain version relationships that content-based methods cannot.
```


```
### "We" + 动词的常见模式

1. **表达观点/主张**
    
    - "We argue that..." (出现多次，如"We argue that the boundary-shift problem not only compromise..."、"We argue that applying CDC to headers is unnecessary...")
    - "We use... to..."
2. **研究方法和过程描述**
    
    - "We process each backup and measure..."
    - "We identify..."
    - "We examine..."
3. **分析和解释**
    
    - "We justify this problem based on..."
    - "We can use the metadata to identify..."
4. **建议和提议**
    
    - "We can reliably locate..."
    - "We eliminate the need for..."

### 特点

1. **学术谨慎性**：通常使用"argue"、"identify"等词表达观点，而非直接断言
    
2. **逻辑严密**：句子往往按照"We [动作] + that + [结论/发现]"的结构，清晰地表达研究过程和结论
    
3. **专业性**：使用专业术语和精确描述，如"We process each backup and measure the shift chunk ratio (SCR)"
```